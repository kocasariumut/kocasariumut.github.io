---
---

@article{stylemc,
  abbr={WACV},
  title={StyleMC: Multi-Channel Based Fast Text-Guided Image Generation and Manipulation},
  author={Umut Kocasari and Alara Dirik and Mert Tiftikci and Pinar Yanardag},
  abstract={Pre-trained GANs have shown great potential for interpretable directions in the latent space. The discovery of such directions is often done in a supervised or self-supervised manner and requires manual annotations which limits their application in practice. On the other hand, unsupervised approaches provide a way to discover interpretable directions without any supervision, but no fine-grained attribute can be discovered. Recent work such as StyleCLIP aims to overcome this limitation by leveraging the power of CLIP, a joint representational model for text and images, for text-driven image manipulation. While promising, these methods take several hours of pre-processing or training time, and require multiple text prompts. In this work, we propose a fast and efficient method for text-guided image generation and manipulation by leveraging the power of StyleGAN2 and CLIP. Our method uses a CLIP-based loss and an identity loss to manipulate images via user-supplied text prompts without changing any of the irrelevant attributes. Unlike previous work, our method requires only 12 seconds of optimization per text prompt and can be used with any pre-trained StyleGAN2 model. We demonstrate the effectiveness of our method with extensive results and comparisons to state-of-the-art approaches.},
  booktitle={Winter Conference on Applications of Computer Vision (WACV)},
  journal={Winter Conference on Applications of Computer Vision},
  pages={1365--1374},
  year={2022},
  month={July},
  pdf={https://arxiv.org/abs/2112.08493},
  teaser={teaser_cat_stylemc.png},
  code={https://github.com/catlab-team/stylemc},
  website={https://catlab-team.github.io/stylemc/},
  selected={true}
  }


@article{creativegan,
  abbr={NeurIPS Workshop},
  title={Exploring Latent Dimensions of Crowd-sourced Creativity},
  author={Umut Kocasari* and Alperen Bag* and Efehan Atici and Pinar Yanardag},
  abstract={Recent research showed that it is possible to find directions in the latent spaces of pre-trained GANs. These directions provide controllable generation and support a wide range of semantic editing operations such as zoom-in or rotation. While existing works focus on discovering directions for semantic image editing, we focus on an abstract property: Creativity. Can we manipulate an image to make it more or less creative? We build our work on the largest AI-based creativity platform Artbreeder where users are able to generate unique images using pre-trained GAN models. We explore the latent dimensions of the images generated on this platform and present a novel framework for manipulating images to make them more creative.},
  booktitle={Machine Learning for Creativity and Design},
  journal={Machine Learning for Creativity and Design},
  pages={1365--1374},
  year={2021},
  month={July},
  teaser={teaser_creativegan.png},
  code={https://github.com/catlab-team/latentcreative},
  pdf={https://arxiv.org/abs/2112.06978},
  website={https://catlab-team.github.io/latentcreative/},
  selected={true}
}
